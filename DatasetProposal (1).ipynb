{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5f276a",
   "metadata": {},
   "source": [
    "Dataset Proposal:\n",
    "\n",
    "For training a model to detect AI-generated text, I will be using https://huggingface.co/datasets/Hello-SimpleAI/HC3/tree/main. This dataset is composed of 24,322 questions with corresponding human answers and answers taken from ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7bf4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Questions: 24322\n",
      "Total Human Answers: 24322\n",
      "Total ChatGPT Answers: 24322\n",
      "----------------- Sample Q/A from Dataset ----------------------\n",
      "Questions: ['Why is every book I hear about a \" NY Times # 1 Best Seller \" ? ELI5 : Why is every book I hear about a \" NY Times # 1 Best Seller \" ? Should n\\'t there only be one \" # 1 \" best seller ? Please explain like I\\'m five.']\n",
      " \n",
      "Human Answers: [['Basically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \" Oscars \" and every \" best seller \" book is basically an \" oscar - winning \" book . May not have won the \" Best film \" , but even if you won the best director or best script , you \\'re still an \" oscar - winning \" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I guess even if you do n\\'t stay there for long , you still achieved the status . Hence , # 1 best seller .', \"If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or both ) , and almost every good or well - publicized book will be # 1 on the NY Times bestseller list for at least a little bit . Kindof like how almost every big or good movies are # 1 at the box office on their opening weekend .\", \"One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't comprehensive , and is pretty well understood by publishers . So publishers can [ buy a few books ] ( URL_0 ) in the right bookstores and send a book to the top of the list for at least a week .\"]]\n",
      " \n",
      "ChatGPT Answers: [['There are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. \\nIt\\'s important to note that the New York Times best seller list is not the only best seller list out there, and there are many other lists that rank the top-selling books in different categories or in different countries. So it\\'s possible that a book could be a best seller on one list but not on another. \\nAdditionally, the term \"best seller\" is often used more broadly to refer to any book that is selling well, regardless of whether it is on a specific best seller list or not. So it\\'s possible that you may hear about a book being a \"best seller\" even if it is not specifically ranked as a number one best seller on the New York Times list or any other list.']]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to clean text by removing backslashes before apostrophes\n",
    "def clean_text(text):\n",
    "    return text.replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"')\n",
    "\n",
    "# Open the JSON Lines file in text mode to read lines directly\n",
    "with open('all.jsonl', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Initialize lists to store the separated data\n",
    "questions = []\n",
    "human_answers = []\n",
    "chatgpt_answers = []\n",
    "\n",
    "# Process each line as a JSON object and extract the desired fields\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "    questions.append(clean_text(data['question']))\n",
    "\n",
    "    # Clean up the human answers\n",
    "    human_cleaned = [clean_text(answer) for answer in data['human_answers']]\n",
    "    human_answers.append(human_cleaned)\n",
    "\n",
    "    # Clean up the ChatGPT answers\n",
    "    chatgpt_cleaned = [clean_text(answer) for answer in data['chatgpt_answers']]\n",
    "    chatgpt_answers.append(chatgpt_cleaned)\n",
    "\n",
    "# Count the total number of questions, human answers, and ChatGPT answers\n",
    "total_questions = len(questions)\n",
    "total_human_answers = len(human_answers)\n",
    "total_chatgpt_answers = len(chatgpt_answers)\n",
    "\n",
    "# Print the total counts\n",
    "print(\"Total Questions:\", total_questions)\n",
    "print(\"Total Human Answers:\", total_human_answers)\n",
    "print(\"Total ChatGPT Answers:\", total_chatgpt_answers)\n",
    "\n",
    "print(\"----------------- Sample Q/A from Dataset ----------------------\")\n",
    "# Print sample from dataset\n",
    "print(\"Questions:\", questions[:1])\n",
    "print(\" \")\n",
    "print(\"Human Answers:\", human_answers[:1])\n",
    "print(\" \")\n",
    "print(\"ChatGPT Answers:\", chatgpt_answers[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ad44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'output.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Open the JSON Lines file in binary mode to read bytes\n",
    "with open('all.jsonl', 'rb') as f:\n",
    "    # Decode the bytes using utf-8 encoding\n",
    "    content = f.read().decode('utf-8', errors='ignore')\n",
    "    # Split the content into lines since it's a JSON Lines file\n",
    "    lines = content.split('\\n')\n",
    "    # Initialize lists to store the separated data\n",
    "    questions = []\n",
    "    human_answers = []\n",
    "    chatgpt_answers = []\n",
    "    \n",
    "    # Process each line as a JSON object and extract the desired fields\n",
    "    for line in lines:\n",
    "        if line.strip():  # Check if the line is not empty\n",
    "            data = json.loads(line)\n",
    "            questions.append(data['question'])\n",
    "            human_answers.append(data['human_answers'])\n",
    "            chatgpt_answers.append(data['chatgpt_answers'])\n",
    "\n",
    "# Zip the lists together to create rows for the CSV file\n",
    "rows = zip(questions, human_answers, chatgpt_answers)\n",
    "\n",
    "# Define the CSV file path and headers\n",
    "csv_file = 'output.csv'\n",
    "headers = ['question', 'human_answer', 'chatgpt_answer']\n",
    "\n",
    "# Write the data to the CSV file\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(headers)  # Write the headers\n",
    "    writer.writerows(rows)  # Write the rows of data\n",
    "\n",
    "print(f\"CSV file '{csv_file}' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c75c3",
   "metadata": {},
   "source": [
    "I created a .csv file to store the original dataset just for ease of use since I am less familiar with .json files. The .csv file created splits the data into questions, human answers, and chatgpt answers.\n",
    "\n",
    "In order to parse the dataset, I will first have to clean the entries for the questions, human answers, and chatgpt answers. The methods I have researched so far include using the BERT tokenizer from the transformers library or the NLTK library, which can remove unwanted characters, punctuation, stopwords, and also normalize the text. I will have to test both methods to see which one better corresponds to my overall goal for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ee9c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV file 'cleaned_dataset.csv' has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "csv_file = \"output.csv\"\n",
    "df_original = pd.read_csv(csv_file)\n",
    "\n",
    "# Separate human and ChatGPT answers into separate DataFrames\n",
    "df_human = df_original[df_original['human_answer'].notnull()].copy()\n",
    "df_chatgpt = df_original[df_original['chatgpt_answer'].notnull()].copy()\n",
    "\n",
    "# Resetting the index for each DataFrame to avoid issues during concatenation\n",
    "df_human.reset_index(drop=True, inplace=True)\n",
    "df_chatgpt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create a new DataFrame to store alternating answers\n",
    "df_alternating = pd.DataFrame(columns=['question', 'answer', 'result'])\n",
    "\n",
    "# Populate the new DataFrame with alternating answers\n",
    "for index, row in df_human.iterrows():\n",
    "    df_alternating.loc[2 * index] = [row['question'], row['human_answer'], 0]\n",
    "    df_alternating.loc[2 * index + 1] = [row['question'], row['chatgpt_answer'], 1]\n",
    "\n",
    "# Define the new CSV file path\n",
    "new_csv_file = \"cleaned_dataset.csv\"\n",
    "\n",
    "# Write the modified data to the new CSV file\n",
    "df_alternating.to_csv(new_csv_file, index=False)\n",
    "\n",
    "print(f\"New CSV file '{new_csv_file}' has been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d1c6170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>['Basically there are many categories of \" Bes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>['There are many different best seller lists t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>['salt is good for not dying in car crashes an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>[\"Salt is used on roads to help melt ice and s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[\"The way it works is that old TV stations got...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  Why is every book I hear about a \" NY Times # ...   \n",
       "2  If salt is so bad for cars , why do we use it ...   \n",
       "3  If salt is so bad for cars , why do we use it ...   \n",
       "4  Why do we still have SD TV channels when HD lo...   \n",
       "\n",
       "                                              answer  result  \n",
       "0  ['Basically there are many categories of \" Bes...       0  \n",
       "1  ['There are many different best seller lists t...       1  \n",
       "2  ['salt is good for not dying in car crashes an...       0  \n",
       "3  [\"Salt is used on roads to help melt ice and s...       1  \n",
       "4  [\"The way it works is that old TV stations got...       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load dataset\n",
    "testdata = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "testdata.head()\n",
    "\n",
    "# result column 0 = human response, 1 = chatgpt response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64a7ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>human_answer</th>\n",
       "      <th>chatgpt_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why is every book I hear about a \" NY Times # ...</td>\n",
       "      <td>['Basically there are many categories of \" Bes...</td>\n",
       "      <td>['There are many different best seller lists t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If salt is so bad for cars , why do we use it ...</td>\n",
       "      <td>['salt is good for not dying in car crashes an...</td>\n",
       "      <td>[\"Salt is used on roads to help melt ice and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do we still have SD TV channels when HD lo...</td>\n",
       "      <td>[\"The way it works is that old TV stations got...</td>\n",
       "      <td>[\"There are a few reasons why we still have SD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n",
       "      <td>[\"You ca n't just go around assassinating the ...</td>\n",
       "      <td>['It is generally not acceptable or ethical to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How was airplane technology able to advance so...</td>\n",
       "      <td>['Wanting to kill the shit out of Germans driv...</td>\n",
       "      <td>['After the Wright Brothers made the first pow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Why is every book I hear about a \" NY Times # ...   \n",
       "1  If salt is so bad for cars , why do we use it ...   \n",
       "2  Why do we still have SD TV channels when HD lo...   \n",
       "3  Why has nobody assassinated Kim Jong - un He i...   \n",
       "4  How was airplane technology able to advance so...   \n",
       "\n",
       "                                        human_answer  \\\n",
       "0  ['Basically there are many categories of \" Bes...   \n",
       "1  ['salt is good for not dying in car crashes an...   \n",
       "2  [\"The way it works is that old TV stations got...   \n",
       "3  [\"You ca n't just go around assassinating the ...   \n",
       "4  ['Wanting to kill the shit out of Germans driv...   \n",
       "\n",
       "                                      chatgpt_answer  \n",
       "0  ['There are many different best seller lists t...  \n",
       "1  [\"Salt is used on roads to help melt ice and s...  \n",
       "2  [\"There are a few reasons why we still have SD...  \n",
       "3  ['It is generally not acceptable or ethical to...  \n",
       "4  ['After the Wright Brothers made the first pow...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load dataset\n",
    "data = pd.read_csv(\"output.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730beaf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
